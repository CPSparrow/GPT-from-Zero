# ä»0å¼€å§‹çš„**ä¸­æ–‡GPT-2**è®­ç»ƒå†’é™©ğŸ˜˜ï¸

## è¸©å‘è®°å½•(to be added)

1. BpeTrainer ä¸­çš„ max_token_length

## todo & notes

ä¸é”™çš„å‚è€ƒèµ„æ–™ï¼š[GPT-2å¤ç°ç¬”è®°](https://zhuanlan.zhihu.com/p/16880416388)

| çŸ­æœŸçš„è®¡åˆ’       |
|:------------|
| å‡†å¤‡æ•°æ®        |
| è®­ç»ƒtokenizer |

## è¿›åº¦(Updates)

> ä»¥å¾€çš„è®°å½•å·²ç»è¢«è½¬ç§»åˆ° [`milestone`](./milestone.md) æ–‡ä»¶ä¸­ã€‚

- 25.3.31:

  é‡æ–°è®­ç»ƒäº†åŸºäºæ–°è¯­æ–™åº“çš„ bpe tokenizer
  ,åŸºæœ¬ä¸Šæ˜¯æŒ‰ç…§
  [HuggingFace Learn çš„ bpe æ•™ç¨‹](https://huggingface.co/learn/nlp-course/chapter6/8?fw=pt#building-a-bpe-tokenizer-from-scratch)
  å®Œæˆçš„ã€‚è¿™é‡Œé¢é€‰æ‹©çš„ 12 ä¸ª epoch æ¯æ¬¡ 40k ä¸ªæ ·æœ¬çš„è®¾ç½®ä¸»è¦æ˜¯æ ¹æ®æœ¬æœºå†…å­˜ 16GB
  çš„æƒ…å†µç¡®å®šçš„ã€‚å› ä¸ºåŸå§‹è¯­æ–™åº“éšæœºæ‰“ä¹±è¿‡ï¼Œæ‰€ä»¥å¯ä»¥è®¤ä¸ºæ•°æ®çš„â€œå¯†åº¦â€æ˜¯æ¯”è¾ƒå¹³å‡çš„ï¼Œå³ç”¨äºè®­ç»ƒçš„æ€»å…±480kæ ·æœ¬å¯¹åº” 1.27GB çš„æ–‡æœ¬

- 25.3.30ï¼š

  æ ¹æ® DeepSeek LLM çš„è®ºæ–‡(è¿æ¥åœ¨åé¢)å†™äº†ä¸€ä¸ªæ ¹æ®æ¨¡å‹æ¶æ„é¢„æµ‹æ¨¡å‹è¶…å‚æ•°å’Œæ•°æ®é›†å¤§å°çš„è„šæœ¬

- 25.03.29:

  > è¡¥å……åŸå…ˆçš„è®­ç»ƒç»“æœï¼šåŸºäºå¤§çº¦ 0.7B tokens ï¼Œ2 epoch è®­ç»ƒçš„ GPT-2 like æ¨¡å‹(300M)ã€‚æ¨¡å‹æ²¡æœ‰ä½“ç°å‡ºå¯¹è¯­è¨€çš„ç†è§£èƒ½åŠ›ï¼Œåªæ˜¯å¤è¯»å’Œé‡å¤æœ€å¼€å§‹çš„è¾“å‡ºã€‚

  æ¥ä¸‹æ¥çš„è®¡åˆ’ ï¼š **å†æ¬¡é‡æ„è¯¥é¡¹ç›®**

  ä¸»è¦çš„å˜åŒ–å°†ä¼šæ˜¯ï¼š

    - é‡æ–°ä¸‹è½½æ›´å¤§çš„æ•°æ®
    - ä½¿ç”¨è¯­æ–™åº“ä»0è®­ç»ƒ tokenizer ,å¯èƒ½è®­ç»ƒ3ä¸ªä¸åŒçš„ç‰ˆæœ¬ğŸ¤”ã€‚
    - ä½¿ç”¨ LLaMa çš„æ¶æ„è®­ç»ƒå°æ¨¡å‹ã€‚è¶…å‚æ•°å¯èƒ½å‚è€ƒ ~~ä¸Šè¿° **å¤ç°ç¬”è®°** ï¼Œæˆ–æ˜¯ä¹‹åå»é˜…è¯»LLaMaçš„è®ºæ–‡ã€‚~~ DeepSeek å¯¹äºScaling
      Laws çš„[ç ”ç©¶è®ºæ–‡](https://arxiv.org/pdf/2401.02954)

- 25.03.17ï¼š

  è¿™ä¸¤æ—¥çš„å·¥ä½œæ€»ç»“ï¼š

    - è¿›è¡Œäº†å¤§çº¦6hçš„è®­ç»ƒ(ä½¿ç”¨autodlçš„vGPU)ï¼Œå› ä¸ºlrå’Œlosséƒ½å¾ˆæ€ªæ‰€ä»¥æå‰åœæ­¢æ£€æŸ¥ä»£ç ã€‚
    - `settings`:å¢åŠ äº†è·¯å¾„éªŒè¯çš„éƒ¨åˆ†
    - `train`:

        1. åˆ å»label smoothing(è™½ç„¶å®éªŒç»“æœä¸è¶³ä»¥å¯¹æ¯”ï¼Œä½†æ˜¯æ€ä¹ˆæƒ³ä¹Ÿæ²¡æœ‰å¿…è¦)
        2. è°ƒæ•´ä¿å­˜è®°å½•çš„ä»£ç 
        3. ä¸ºâ€œå•æœºå¤šå¡â€ä»¥åŠâ€œä»ä¸­æ–­çš„åœ°æ–¹ç»§ç»­è®­ç»ƒâ€åšäº†å‡†å¤‡ï¼Œä¸è¿‡éƒ½æ˜¯æ²¡æœ‰éªŒè¯çš„ä»£ç 

## æ•°æ®æ¥æº(æœªæ›´æ–°)

- ä¼ ç»Ÿæ–‡åŒ–: è¿˜éœ€æ¸…æ´—ï¼Œæ‡’å¾—æå°±ä¸æäº†
- **åŸºç¡€è¯­æ–™**:ç›®å‰å°±ç”¨è¿™ä¸ªäº†ï¼Œè´¨é‡æ¯”è¾ƒé«˜çš„ä¸­æ–‡è¯­æ–™ï¼Œç½‘å®‰å¹³å°ä¸‹è½½çš„
- cci: æ¥æºåŒä¸Šï¼Œè¿˜æ²¡ä¸‹è½½æ¥
- oscar: æ¥è‡ªmnbvcçš„crawleræ–‡ä»¶å¤¹
- ~~[CLUECorpus2020](https://github.com/CLUEbenchmark/CLUECorpus2020)~~ é€šè¿‡ç™¾åº¦ç½‘ç›˜æä¾›ï¼Œæ‰€ä»¥ä¸æƒ³æ
- [liwu/MNBVC](https://huggingface.co/datasets/liwu/MNBVC) è¶…å¤§è§„æ¨¡æ•°æ®é›†ï¼Œoscaræ˜¯common crawlçš„æ¸…æ´—ï¼Œå¯ä»¥ä½œä¸ºåˆæ­¥é¢„è®­ç»ƒçš„è¯­æ–™ã€‚
- [c4](https://hf-mirror.com/datasets/allenai/c4/tree/main/en) å¯ä»¥ä½œä¸ºè‹±æ–‡è®­ç»ƒ
- [smoltalk](https://opencsg.com/datasets/OpenCSG/smoltalk_chinese/files/main/data) ä½œä¸ºsftè¯­æ–™

## ç¯å¢ƒé…ç½®ç¬”è®°

ä¸»è¦æ˜¯ä¸ºäº†ä¸Šäº‘å’Œé‡ç½®çš„æ—¶å€™æ–¹ä¾¿æŸ¥é˜…ï¼š

- cuda/nvcc >= 12.4

installation:

```shell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
pip install transformers datasets accelerate optimum
pip install pandas ninja packaging
```

validation before flash attention 2:

```shell
ninja --version
echo $?
```

éšåæ‰‹åŠ¨å®‰è£…nvidia/apexå’Œflash attention 2:

~~apex:~~
> ç›®å‰çš„ä»£ç ä½¿ç”¨çš„æ˜¯ `adamw_torch_fused` ï¼Œä¸éœ€è¦å®‰è£…apex

```shell
git clone https://github.com/NVIDIA/apex
cd apex
NVCC_APPEND_FLAGS="--threads 4" pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings "--build-option=--cpp_ext --cuda_ext --parallel 4" ./
```

flash attentionï¼š

```shell
MAX_JOBS=4 pip install flash-attn --no-build-isolation
```

å®‰è£…åæ¸…ç†ç¼“å­˜ï¼š
pip:

```shell
pip cache purge
```

conda:
è¿è¡Œå‰æŸ¥çœ‹ï¼š

```shell
conda clean --dry-run --all
```

```shell
conda clean --tarballs
conda clean --packages
```
